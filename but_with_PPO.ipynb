{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "#from stable_baseline3.stable_baselines3.ppo import ppo\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import concat\n",
    "import time\n",
    "#import tensorflow_probability as tfp\n",
    "import tensorflow.keras.losses as kls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MowerEnv2():\n",
    "    def __init__(self, info, render_mode = True): #info 0 = len, 1 = number of agents (up to 4)\n",
    "        self.render_mode = render_mode\n",
    "        self.len = info[0]\n",
    "        self.agents = info[1]\n",
    "        if render_mode == True:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((720, 720))\n",
    "        # Actions we can up down left right\n",
    "        # Set length\n",
    "        self.direct = [[-1, 0], [0, 1], [1, 0], [0, -1]]\n",
    "\n",
    "    def step(self, action):\n",
    "        ret = []\n",
    "        for j in range(self.agents):\n",
    "            # Apply action (no walls for now)\n",
    "            x = self.all[j][0] + self.direct[action[j]][0]\n",
    "            y = self.all[j][1] + self.direct[action[j]][1]\n",
    "            if self.isValid(x, y) == 0:\n",
    "                x = self.all[j][0]\n",
    "                y = self.all[j][1]\n",
    "            if self.state[x][y][0] == 1:\n",
    "                self.area_clear += 1\n",
    "                reward = 5.0 * np.power(4, self.area_clear/self.max_area)\n",
    "            else:\n",
    "                reward = -0.5\n",
    "                self.running_length -= 1\n",
    "            self.state[x][y][0] = 0\n",
    "            self.all[j][0] = x\n",
    "            self.all[j][1] = y\n",
    "\n",
    "            # update boundries\n",
    "            for i in range(4):\n",
    "                self.all[j][i+2] = self.isValid(x + self.direct[i][0], y + self.direct[i][1])\n",
    "            temp = self.cheats(x, y)\n",
    "            self.all[j][6]= self.all[j][7]= self.all[j][8]= self.all[j][9] = 0\n",
    "            for p in temp:\n",
    "                self.all[j][6+p] = 1\n",
    "            # Check if  done\n",
    "            if self.running_length < 0:\n",
    "                done = True\n",
    "            else:\n",
    "                if self.finished(): #change back to self.finished()\n",
    "                    if not done:\n",
    "                        reward = self.max_area * 20\n",
    "                    else:\n",
    "                        reward = 0\n",
    "                    done = True\n",
    "                else:\n",
    "                    done = False\n",
    "            ret.append(reward)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        # Return step information\n",
    "        return (ret, done)\n",
    "\n",
    "    def isValid(self, x, y):\n",
    "        if x < 0 or x < 0 or x >= self.len or y < 0 or y >= self.len:\n",
    "            return 0 #return False\n",
    "        if self.state[x][y][1] == 1:\n",
    "            return 0\n",
    "        return 1 #return true\n",
    "\n",
    "    def cheats(self, posx, posy):\n",
    "        # Next action:\n",
    "        # (feed the observation to your agent here)\n",
    "        calc = np.zeros((16, 16))\n",
    "        list = deque()\n",
    "        calc[posx][posy] = 1\n",
    "        list.append([posx, posy])\n",
    "        move = []\n",
    "        while True: #has multiple paths issues, but should be irrelevent\n",
    "            size = len(list)\n",
    "            for z in range(size):\n",
    "                tuple = list.popleft()\n",
    "                for i in range(4):\n",
    "                    x = tuple[0] + self.direct[i][0]\n",
    "                    y = tuple[1] + self.direct[i][1]\n",
    "                    if x >= 0 and x < 16 and y >=0 and y < 16:\n",
    "                        if self.state[x][y][1] == 0 and calc[x][y] == 0:\n",
    "                            calc[x][y] = 1\n",
    "                            choice = i\n",
    "                            if len(tuple) == 3:\n",
    "                                choice = tuple[2]\n",
    "                            if self.state[x][y][0] == 0:\n",
    "                                ret = [x, y, choice]\n",
    "                                list.append(ret)\n",
    "                            else:\n",
    "                                move.append(choice)\n",
    "                                break\n",
    "\n",
    "            if len(move) > 0:\n",
    "                break\n",
    "        return move\n",
    "\n",
    "    def finished(self):\n",
    "        return self.area_clear==self.max_area\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        if self.render_mode == True:\n",
    "            pygame.event.get()\n",
    "            gap = 720//self.len\n",
    "            for i in range(0, 720, gap):\n",
    "                for j in range(0, 720, gap):\n",
    "                    if self.state[i//gap][j//gap][0] == 0:\n",
    "                        color = (255, 255, 255)\n",
    "                    elif self.state[i//gap][j//gap][0] == 1:\n",
    "                        color = (255, 255,0)\n",
    "                    for k in range(self.agents):\n",
    "                        if self.all[k][0] == i//gap and self.all[k][1] == j//gap:\n",
    "                            color = (255, 0, 0)\n",
    "                    if self.state[i//gap][j//gap][1] == 1:\n",
    "                        color = (0, 0, 0)\n",
    "                    pygame.draw.rect(self.screen, color, (j, i, gap, gap))\n",
    "            pygame.display.update()\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Set starting state\n",
    "        self.state = np.copy(combined_data)\n",
    "        self.all = np.zeros((self.agents, 10), dtype = int)\n",
    "\n",
    "        for i in range(self.agents):# Set position\n",
    "            all[i][0] = corners[i][0]\n",
    "            all[i][1] = corners[i][1]\n",
    "\n",
    "            # Set border detect 0 = blocked, 1 = valid\n",
    "            for j in range(4):\n",
    "                all[i][j+2] = self.isValid(all[i][0] + self.direct[j][0], all[i][1] + self.direct[j][1])\n",
    "            temp = self.cheats(all[i][0], all[i][1])\n",
    "            all[i][6]= all[i][7]= all[i][8]= all[i][9] = 0\n",
    "            for p in temp:\n",
    "                all[i][6+p] = 1\n",
    "\n",
    "        self.running_length = ((self.len) * (self.len) * (1 + self.agents)) // 2\n",
    "        self.area_clear = 0\n",
    "        self.max_area = np.sum(self.state['grid'][0])\n",
    "        return self.state, {}\n",
    "\n",
    "    def get_state(self):\n",
    "        return (self.state, self.all)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "grass_data = [[0,0,1,0,1,0,1,0,0,1,1,0,1,0,0,0],\n",
    "[0,0,1,0,1,0,1,1,0,1,0,0,1,0,0,1],\n",
    "[1,1,0,0,1,0,0,0,1,1,0,0,0,1,0,0],\n",
    "[0,0,0,1,0,1,0,1,0,0,0,1,1,0,1,0],\n",
    "[0,1,1,0,0,0,1,0,0,1,0,0,1,0,0,0],\n",
    "[1,1,0,0,1,0,0,0,0,0,1,1,1,0,0,0],\n",
    "[1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0],\n",
    "[0,1,1,0,0,0,1,0,0,0,1,0,1,0,0,0],\n",
    "[0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,0],\n",
    "[1,0,0,1,0,1,0,1,0,1,1,0,1,0,1,0],\n",
    "[1,0,0,0,1,1,1,0,1,0,0,0,0,0,1,0],\n",
    "[0,1,0,0,1,0,1,1,1,0,1,1,0,0,0,0],\n",
    "[1,0,0,1,1,0,0,1,0,1,0,0,0,0,1,0],\n",
    "[1,0,0,1,0,0,1,0,1,0,1,1,1,1,0,0],\n",
    "[1,0,1,0,1,1,0,1,0,1,0,0,1,0,0,0],\n",
    "[1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "walls_data = [[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "[0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0],\n",
    "[0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0],\n",
    "[0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,0],\n",
    "[0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,1],\n",
    "[0,0,1,1,0,0,0,0,1,0,0,0,0,1,0,0],\n",
    "[0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0],\n",
    "[0,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0],\n",
    "[0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0],\n",
    "[0,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0],\n",
    "[0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0],\n",
    "[0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0],\n",
    "[0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0],\n",
    "[0,0,1,0,1,1,0,0,0,1,0,0,0,0,1,0],\n",
    "[0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0],\n",
    "[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]]\n",
    "corners = [[0, 0], [1, 1], [1, 0], [0, 1]]\n",
    "walls_data = [] #delete later\n",
    "for i in range(16):\n",
    "    walls_data.append([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "corners = [[0, 0], [1, 1], [1, 0], [0, 1]]\n",
    "combined_data = []\n",
    "for i in range(16):\n",
    "    combined_data.append([])\n",
    "    for j in range(16):\n",
    "        combined_data[i].append([grass_data[i][j], walls_data[i][j]])\n",
    "combined_data = np.array(combined_data, dtype = int)\n",
    "#@title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass critic(keras.Model):\\n    def __init__(self):\\n        super().__init__()\\n        self.m1 = keras.Sequential([\\n            keras.layers.Input((16, 16, 2)), #change later\\n            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\\n            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\\nactivation=\\'relu\\',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\\n            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\\nactivation=\\'relu\\',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Flatten(data_format=\"channels_last\"),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n        self.m2 = keras.Sequential([\\n            keras.layers.Input((10,)),\\n            keras.layers.Dense(units=64, activation = \\'relu\\', kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n        self.m3 = keras.Sequential([\\n            keras.layers.Input((128,)),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Dense(units=1, activation=\"linear\", kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n\\n    def call(self, input_image, input_data):\\n        I = self.m1(input_image)\\n        D = self.m2(input_data)\\n        O = self.m3(concat([I,D],1))\\n        return O\\n    \\n\\nclass actor(tf.keras.Model):\\n    def __init__(self):\\n        super().__init__()\\n        self.m1 = keras.Sequential([\\n            keras.layers.Input((16, 16, 2)), #change later\\n            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\\n            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\\nactivation=\\'relu\\',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\\n            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\\nactivation=\\'relu\\',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Flatten(data_format=\"channels_last\"),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n        self.m2 = keras.Sequential([\\n            keras.layers.Input((10,)),\\n            keras.layers.Dense(units=64, activation = \\'relu\\', kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n        self.m3 = keras.Sequential([\\n            keras.layers.Input((128,)),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\\n            tf.keras.layers.Dropout(.2),\\n            keras.layers.Dense(units=4, activation=\"softmax\", kernel_regularizer=keras.regularizers.L2(0.01))\\n        ])\\n\\n    def call(self, input_image, input_data):\\n        I = self.m1(input_image)\\n        D = self.m2(input_data)\\n        O = self.m3(concat([I,D],1))\\n        return O\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class critic(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = keras.Sequential([\n",
    "            keras.layers.Input((16, 16, 2)), #change later\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\"),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\"),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            keras.layers.Flatten(data_format=\"channels_last\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\")\n",
    "        ])\n",
    "        self.m2 = keras.Sequential([\n",
    "            keras.layers.Input((10,)),\n",
    "            keras.layers.Dense(units=64, activation = 'relu')\n",
    "        ])\n",
    "        self.m3 = keras.Sequential([\n",
    "            keras.layers.Input((128,)),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "            keras.layers.Dense(units=1, activation=\"linear\")\n",
    "        ])\n",
    "\n",
    "    def call(self, input_image, input_data):\n",
    "        I = self.m1(input_image)\n",
    "        D = self.m2(input_data)\n",
    "        O = self.m3(concat([I,D],1))\n",
    "        return O\n",
    "    \n",
    "\n",
    "class actor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = keras.Sequential([\n",
    "            keras.layers.Input((16, 16, 2)), #change later\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\"),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\"),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            keras.layers.Flatten(data_format=\"channels_last\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\")\n",
    "        ])\n",
    "        self.m2 = keras.Sequential([\n",
    "            keras.layers.Input((10,)),\n",
    "            keras.layers.Dense(units=64, activation = 'relu')\n",
    "        ])\n",
    "        self.m3 = keras.Sequential([\n",
    "            keras.layers.Input((128,)),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "            keras.layers.Dense(units=4, activation=\"softmax\")\n",
    "        ])\n",
    "\n",
    "    def call(self, input_image, input_data):\n",
    "        I = self.m1(input_image)\n",
    "        D = self.m2(input_data)\n",
    "        O = self.m3(concat([I,D],1))\n",
    "        return O\n",
    "\"\"\"\n",
    "class critic(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = keras.Sequential([\n",
    "            keras.layers.Input((16, 16, 2)), #change later\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Flatten(data_format=\"channels_last\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "        self.m2 = keras.Sequential([\n",
    "            keras.layers.Input((10,)),\n",
    "            keras.layers.Dense(units=64, activation = 'relu', kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "        self.m3 = keras.Sequential([\n",
    "            keras.layers.Input((128,)),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Dense(units=1, activation=\"linear\", kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "\n",
    "    def call(self, input_image, input_data):\n",
    "        I = self.m1(input_image)\n",
    "        D = self.m2(input_data)\n",
    "        O = self.m3(concat([I,D],1))\n",
    "        return O\n",
    "    \n",
    "\n",
    "class actor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = keras.Sequential([\n",
    "            keras.layers.Input((16, 16, 2)), #change later\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.ZeroPadding2D(padding = (1, 1), data_format=\"channels_last\"),\n",
    "            keras.layers.Conv2D(filters = 16,kernel_size = (3,3),strides = (1,1),\n",
    "activation='relu',data_format=\"channels_last\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Flatten(data_format=\"channels_last\"),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "        self.m2 = keras.Sequential([\n",
    "            keras.layers.Input((10,)),\n",
    "            keras.layers.Dense(units=64, activation = 'relu', kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "        self.m3 = keras.Sequential([\n",
    "            keras.layers.Input((128,)),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2(0.01)),\n",
    "            tf.keras.layers.Dropout(.2),\n",
    "            keras.layers.Dense(units=4, activation=\"softmax\", kernel_regularizer=keras.regularizers.L2(0.01))\n",
    "        ])\n",
    "\n",
    "    def call(self, input_image, input_data):\n",
    "        I = self.m1(input_image)\n",
    "        D = self.m2(input_data)\n",
    "        O = self.m3(concat([I,D],1))\n",
    "        return O\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.a_opt = keras.optimizers.Adam(learning_rate=0.0002) # or 0.00015\n",
    "        self.c_opt = keras.optimizers.Adam(learning_rate=0.0002)\n",
    "        self.actor = actor()\n",
    "        self.critic = critic()\n",
    "        self.clip_pram = 0.2\n",
    "\n",
    "    def act(self, stateI, stateN):\n",
    "        prob = self.actor(np.expand_dims(stateI, 0), np.expand_dims(stateN, 0))\n",
    "        prob = prob.numpy()\n",
    "        #dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
    "        #action = dist.sample()\n",
    "        #return int(action.numpy()[0])\n",
    "        return np.random.choice(a = [0, 1, 2, 3], size = 1, p = prob.flatten())\n",
    "    \n",
    "    def learn(self, statesI, statesN, actions,  adv , old_probs, discnt_rewards):\n",
    "        discnt_rewards = tf.reshape(discnt_rewards, (len(discnt_rewards),))\n",
    "        adv = tf.reshape(adv, (len(adv),))\n",
    "\n",
    "        #old_p = old_probs\n",
    "\n",
    "        #old_p = tf.reshape(old_p, (len(old_p),2))\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "            p = self.actor(tf.stack(statesI, 0),tf.stack(statesN, 0), training=True)\n",
    "            v =  self.critic(np.stack(statesI, 0),np.stack(statesN, 0),training=True)\n",
    "            #v = tf.reshape(v, (len(v),))\n",
    "            #td = tf.math.subtract(discnt_rewards, v)\n",
    "            c_loss = 0.5 * kls.mean_squared_error(np.expand_dims(discnt_rewards, 0), v)\n",
    "            a_loss = self.actor_loss(p, actions, adv, old_probs, c_loss)\n",
    "            \n",
    "        grads1 = tape1.gradient(a_loss, self.actor.trainable_variables)\n",
    "        grads2 = tape2.gradient(c_loss, self.critic.trainable_variables)\n",
    "        self.a_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n",
    "        self.c_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n",
    "        return a_loss, c_loss\n",
    "    def actor_loss(self, probs, actions, adv, old_probs, closs):\n",
    "        \n",
    "        probability = probs      \n",
    "        entropy = tf.reduce_mean(tf.math.negative(tf.math.multiply(probability,tf.math.log(probability))))\n",
    "        #print(probability)\n",
    "        #print(entropy)\n",
    "        sur1 = []\n",
    "        sur2 = []\n",
    "        \n",
    "        for pb, t, op, a in zip(probability, adv, old_probs, actions):\n",
    "                        t =  tf.constant(t)\n",
    "                        #op =  tf.constant(op)\n",
    "                        #print(f\"t{t}\")\n",
    "                        #ratio = tf.math.exp(tf.math.log(pb + 1e-10) - tf.math.log(op + 1e-10))\n",
    "                        ratio = tf.math.divide(pb[a],op[a])\n",
    "                        #print(f\"ratio{ratio}\")\n",
    "                        s1 = tf.math.multiply(ratio,t)\n",
    "                        #print(f\"s1{s1}\")\n",
    "                        s2 =  tf.math.multiply(tf.clip_by_value(ratio, 1.0 - self.clip_pram, 1.0 + self.clip_pram),t)\n",
    "                        #print(f\"s2{s2}\")\n",
    "                        sur1.append(s1)\n",
    "                        sur2.append(s2)\n",
    "\n",
    "        sr1 = tf.stack(sur1)\n",
    "        sr2 = tf.stack(sur2)\n",
    "        \n",
    "        #closs = tf.reduce_mean(tf.math.square(td))\n",
    "        loss = tf.math.negative(tf.reduce_mean(tf.math.minimum(sr1, sr2)) - closs + 0.0001 * entropy)\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_reward(env):\\n    total_reward = 0\\n    state = env.reset()\\n    done = False\\n    while not done:\\n        action = np.argmax(agentoo7.actor(np.array([state])).numpy())\\n        next_state, reward, done, _ = env.step(action)\\n        state = next_state\\n        total_reward += reward\\n\\n    return total_reward\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#useless\n",
    "\"\"\"\n",
    "def test_reward(env):\n",
    "    total_reward = 0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(agentoo7.actor(np.array([state])).numpy())\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    return total_reward\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(reward, done, value, gamma):\n",
    "    g = 0\n",
    "    lmbda = 0.95\n",
    "    returns = []\n",
    "\n",
    "    for i in reversed(range(len(reward))):\n",
    "        delta = reward[i] + gamma * value[i + 1] * done[i] - value[i]\n",
    "        g = delta + gamma * lmbda * done[i] * g\n",
    "        returns.append(g + value[i])\n",
    "\n",
    "    returns.reverse()\n",
    "    adv = np.array(returns, dtype=np.float32) - value[:-1]\n",
    "    adv = (adv - np.mean(adv)) / (np.std(adv) + 1e-10)\n",
    "    returns = np.array(returns, dtype=np.float32)\n",
    "    return returns, adv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy  = [agent(),agent(),agent(),agent()]\n",
    "for i in range(4):\n",
    "    copy[i].critic.set_weights(agent_list[i].critic.get_weights())\n",
    "    copy[i].actor.set_weights(agent_list[i].actor.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    copy[i].critic.set_weights(agent_list[i].critic.get_weights())\n",
    "    copy[i].actor.set_weights(agent_list[i].actor.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(369)\n",
    "agent_list = [agent(),agent(),agent(),agent()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: -45.23266351076669\n",
      "7: -37.4552417005677\n",
      "11: -24.272375283951035\n",
      "15: -21.939218665790303\n",
      "19: -1.8959848746324284\n",
      "23: 16.751326745405752\n",
      "27: 33.83466812789782\n",
      "31: 46.107850343037704\n",
      "35: 48.02731903508372\n",
      "39: 53.05615060831428\n",
      "43: 63.25917083053732\n",
      "47: 69.26065744626835\n",
      "51: 71.7922668001573\n",
      "55: 73.85904389501513\n",
      "59: 81.61523524076046\n",
      "63: 83.32098250549483\n",
      "67: 94.17755336434811\n",
      "71: 104.88856214333194\n",
      "75: 113.16158512412309\n",
      "79: 126.94137569668958\n",
      "83: 135.80569999323137\n",
      "87: 145.90781842481118\n",
      "91: 160.56088579163546\n",
      "95: 174.3958342112552\n",
      "99: 187.8217439060194\n",
      "103: 196.84858612146638\n",
      "107: 205.35330786327663\n",
      "111: 212.72605784888054\n",
      "115: 223.8738393378396\n",
      "119: 231.0652743092811\n",
      "123: 239.78854556825482\n",
      "127: 247.5824349180899\n",
      "131: 257.79202903117687\n",
      "135: 266.7704668037273\n",
      "139: 273.84746035494055\n",
      "143: 282.35475947624104\n",
      "147: 287.02243963142627\n",
      "151: 292.750025479691\n",
      "155: 297.3019657452828\n",
      "159: 303.4295913406553\n",
      "163: 309.6349009724363\n",
      "167: 315.7802086821695\n",
      "171: 319.9003086757623\n",
      "175: 325.9088659169566\n",
      "179: 332.23036523705736\n",
      "183: 336.9005296425736\n",
      "187: 340.9032960991935\n",
      "191: 347.44713724726336\n",
      "195: 353.17538736641444\n",
      "199: 359.3864845066591\n",
      "203: 364.2385018411643\n",
      "207: 369.3684228654741\n",
      "211: 374.1918643812044\n",
      "215: 378.808905473347\n",
      "219: 383.24149321175435\n",
      "223: 388.45300541735463\n",
      "227: 392.98293489912663\n",
      "231: 397.6932355571417\n",
      "235: 402.19309454564564\n",
      "239: 406.84124040130575\n",
      "243: 409.99152846425363\n",
      "247: 414.82348065058073\n",
      "251: 418.2911264980779\n",
      "255: 423.5718947981668\n",
      "259: 426.84740315503933\n",
      "263: 430.3875426312045\n",
      "267: 435.480939017242\n",
      "271: 439.4717202862143\n",
      "275: 441.65652677092675\n",
      "279: 444.4854808176534\n",
      "283: 448.3405542435675\n",
      "287: 451.21163927531984\n",
      "291: 454.7588920522006\n",
      "295: 457.4843347562242\n",
      "299: 460.8500963839342\n",
      "303: 464.0440201890664\n",
      "307: 465.9993771038313\n",
      "311: 467.87034813549894\n",
      "315: 469.64371860142916\n",
      "319: 472.3370230153504\n",
      "323: 475.2750925959131\n",
      "327: 478.1334556179716\n",
      "331: 481.9847677602562\n",
      "335: 485.15391147543977\n",
      "339: 486.9605556955139\n",
      "343: 489.9094511289662\n",
      "347: 492.0075737100071\n",
      "351: 494.0797908398165\n",
      "355: 496.745505942098\n",
      "359: 499.71235358701523\n",
      "363: 502.12028162871337\n",
      "367: 504.5303600514217\n",
      "371: 506.6298728451453\n",
      "375: 509.21370237607397\n",
      "379: 512.4493610308788\n",
      "383: 515.1814516067648\n",
      "387: 518.0010877651088\n",
      "391: 520.8168032437756\n",
      "395: 522.9582625625306\n",
      "399: 524.7722981726428\n",
      "403: 527.2646789848095\n",
      "407: 529.6690734909523\n",
      "411: 531.6393271871542\n",
      "415: 534.1562551418275\n",
      "419: 535.819427371917\n",
      "423: 538.4677567876992\n",
      "427: 541.463037643175\n",
      "431: 544.1811366815434\n",
      "435: 546.5230271408783\n",
      "439: 549.0641790160679\n",
      "443: 551.2840926033742\n",
      "447: 553.4607328149973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     prob \u001b[39m=\u001b[39m agent_list[j]\u001b[39m.\u001b[39mactor(np\u001b[39m.\u001b[39mexpand_dims(stateI,\u001b[39m0\u001b[39m), np\u001b[39m.\u001b[39mexpand_dims(stateN[j],\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     40\u001b[0m     probs[j]\u001b[39m.\u001b[39mappend(prob)\n\u001b[1;32m---> 42\u001b[0m _, reward, done, _, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep([actions[j][i] \u001b[39mfor\u001b[39;49;00m j \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(number)])\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number):\n\u001b[0;32m     45\u001b[0m     rewards[j]\u001b[39m.\u001b[39mappend(reward[j])\n",
      "Cell \u001b[1;32mIn[2], line 45\u001b[0m, in \u001b[0;36mMowerEnv2.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m     44\u001b[0m     \u001b[39mall\u001b[39m[i\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m\u001b[39m+\u001b[39mj\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misValid(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirect[i][\u001b[39m0\u001b[39m], y \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirect[i][\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 45\u001b[0m temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheats(x, y)\n\u001b[0;32m     46\u001b[0m \u001b[39mall\u001b[39m[\u001b[39m6\u001b[39m\u001b[39m+\u001b[39mj\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m]\u001b[39m=\u001b[39m \u001b[39mall\u001b[39m[\u001b[39m7\u001b[39m\u001b[39m+\u001b[39mj\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m]\u001b[39m=\u001b[39m \u001b[39mall\u001b[39m[\u001b[39m8\u001b[39m\u001b[39m+\u001b[39mj\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m]\u001b[39m=\u001b[39m \u001b[39mall\u001b[39m[\u001b[39m9\u001b[39m\u001b[39m+\u001b[39mj\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m temp:\n",
      "Cell \u001b[1;32mIn[2], line 84\u001b[0m, in \u001b[0;36mMowerEnv2.cheats\u001b[1;34m(self, posx, posy)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mlist\u001b[39m\u001b[39m.\u001b[39mappend([posx, posy])\n\u001b[0;32m     83\u001b[0m move \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 84\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m: \u001b[39m#has multiple paths issues, but should be irrelevent\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(size):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "target = False\n",
    "number = 1\n",
    "wid = 16\n",
    "env = MowerEnv2([wid, number], False)\n",
    "rew_avg = 0\n",
    "for s in range(steps):\n",
    "    #if target == True:\n",
    "    #    break\n",
    "    total_rew = 0\n",
    "    done = False\n",
    "    rewards = []\n",
    "    statesI = []\n",
    "    statesN = []\n",
    "    actions = []\n",
    "    probs = []\n",
    "    dones = []\n",
    "    values = []\n",
    "    for j in range(number):\n",
    "        rewards.append([])\n",
    "        statesN.append([])\n",
    "        actions.append([])\n",
    "        probs.append([])\n",
    "        values.append([])\n",
    "\n",
    "    env.reset()\n",
    "    i = 0\n",
    "    while True:\n",
    "        stateI, stateN = env.get_state()\n",
    "        stateI = np.copy(stateI)\n",
    "        stateN = np.copy(stateN)\n",
    "        statesI.append(stateI)\n",
    "        for j in range(number):\n",
    "            action = agent_list[j].act(stateI, stateN[j])[0]\n",
    "            actions[j].append(action)\n",
    "            value = agent_list[j].critic(np.expand_dims(stateI,0), np.expand_dims(stateN[j],0)).numpy()[0]\n",
    "            values[j].append(value)\n",
    "            statesN[j].append(stateN[j])\n",
    "            prob = agent_list[j].actor(np.expand_dims(stateI,0), np.expand_dims(stateN[j],0)).numpy()[0]\n",
    "            probs[j].append(prob)\n",
    "\n",
    "        _, reward, done, _, _ = env.step([actions[j][i] for j in range(number)])\n",
    "\n",
    "        for j in range(number):\n",
    "            rewards[j].append(reward[j])\n",
    "            total_rew += reward[j]\n",
    "            #actions.append(tf.one_hot(action, 2, dtype=tf.int32).numpy().tolist())\n",
    "\n",
    "        dones.append(1-done)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    stateI, stateN = env.get_state()\n",
    "    stateI = np.copy(stateI)\n",
    "    stateN = np.copy(stateN)\n",
    "    for j in range(number):\n",
    "        value = agent_list[j].critic(np.expand_dims(stateI,0), np.expand_dims(stateN[j],0)).numpy()[0]\n",
    "        values[j].append(value)\n",
    "    #np.reshape(probs, (len(probs),2))\n",
    "    #probs = np.stack(probs, axis=0)\n",
    "    rets = []\n",
    "    advs = []\n",
    "    for j in range(number):\n",
    "        returns, adv  = preprocess1(rewards[j], dones, values[j], 0.995)\n",
    "        rets.append(returns)\n",
    "        advs.append(adv)\n",
    "\n",
    "    for epocs in range(5):\n",
    "        for j in range(number):\n",
    "            al,cl = agent_list[j].learn(statesI, statesN[j], actions[j], advs[j], probs[j], rets[j])\n",
    "        # print(f\"al{al}\")\n",
    "        # print(f\"cl{cl}\")\n",
    "\n",
    "    rew_avg += total_rew\n",
    "    if s % 4 == 3:\n",
    "        print(f\"{s}: {rew_avg/(s+1)}\")\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = [-91.40332473078743\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-24.976366240561006\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "37.79446623850616\n",
    ",\n",
    "-56.48096115798328\n",
    ",\n",
    "1.9173916039322512\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "-24.976366240561013\n",
    ",\n",
    "60.59755802567484\n",
    ",\n",
    "-4.952376633358192\n",
    ",\n",
    "144.15406580582882\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "144.1540658058288\n",
    ",\n",
    "144.15406580582882\n",
    ",\n",
    "1.9173916039322574\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "45.28600162288954\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "15.958150733042725\n",
    ",\n",
    "15.958150733042729\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "-31.460564013816054\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-68.45951938699949\n",
    ",\n",
    "-68.45951938699949\n",
    ",\n",
    "-80.09707131545711\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-85.79101448924057\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-68.45951938699949\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "8.887082921177253\n",
    ",\n",
    "317.05868406413435\n",
    ",\n",
    "8.88708292117725\n",
    ",\n",
    "60.59755802567484\n",
    ",\n",
    "210.2528266950486\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "45.28600162288957\n",
    ",\n",
    "-24.976366240561006\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-4.95237663335819\n",
    ",\n",
    "15.958150733042714\n",
    ",\n",
    "8.887082921177253\n",
    ",\n",
    "-37.85179913161821\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "-4.952376633358185\n",
    ",\n",
    "-62.513483811985886\n",
    ",\n",
    "-74.32030783109575\n",
    ",\n",
    "-31.460564013816054\n",
    ",\n",
    "-44.151404381092576\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-4.952376633358199\n",
    ",\n",
    "-24.976366240561006\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "-11.723654368042652\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "37.794466238506146\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "23.132069594597723\n",
    ",\n",
    "15.958150733042714\n",
    ",\n",
    "-11.72365436804264\n",
    ",\n",
    "-31.460564013816057\n",
    ",\n",
    "68.42077201771373\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "-68.45951938699949\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-4.952376633358183\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "1.917391603932252\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-68.45951938699949\n",
    ",\n",
    "-31.460564013816054\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "-31.460564013816068\n",
    ",\n",
    "-4.952376633358191\n",
    ",\n",
    "-18.39785363889282\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "15.958150733042714\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-18.397853638892812\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-31.460564013816054\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-44.15140438109258\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-44.151404381092576\n",
    ",\n",
    "-31.460564013816068\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "92.57980620350651\n",
    ",\n",
    "8.88708292117725\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "126.46381782255895\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "-11.723654368042654\n",
    ",\n",
    "-31.46056401381606\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "52.88650389863514\n",
    ",\n",
    "-4.952376633358188\n",
    ",\n",
    "8.887082921177253\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "-11.723654368042654\n",
    ",\n",
    "8.887082921177239\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "171.666099363308\n",
    ",\n",
    "126.46381782255892\n",
    ",\n",
    "162.3626776217865\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "153.19263718973983\n",
    ",\n",
    "52.88650389863514\n",
    ",\n",
    "30.410335508808643\n",
    ",\n",
    "52.88650389863513\n",
    ",\n",
    "37.79446623850614\n",
    ",\n",
    "8.88708292117725\n",
    ",\n",
    "30.410335508808657\n",
    ",\n",
    "92.57980620350651\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "60.59755802567485\n",
    ",\n",
    "135.24507862442542\n",
    ",\n",
    "23.13206959459771\n",
    ",\n",
    "230.39828004442384\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "76.3577772775547\n",
    ",\n",
    "162.36267762178653\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "181.10484249012492\n",
    ",\n",
    "-4.952376633358189\n",
    ",\n",
    "126.46381782255892\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "84.41022893730099\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "126.4638178225589\n",
    ",\n",
    "15.958150733042729\n",
    ",\n",
    "52.88650389863514\n",
    ",\n",
    "8.88708292117725\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "162.36267762178653\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "37.794466238506146\n",
    ",\n",
    "-4.952376633358199\n",
    ",\n",
    "-11.723654368042652\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "15.958150733042732\n",
    ",\n",
    "8.887082921177253\n",
    ",\n",
    "-4.952376633358188\n",
    ",\n",
    "23.132069594597716\n",
    ",\n",
    "30.410335508808686\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "60.59755802567484\n",
    ",\n",
    "153.19263718973983\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "60.59755802567483\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "60.59755802567486\n",
    ",\n",
    "126.46381782255892\n",
    ",\n",
    "-11.723654368042654\n",
    ",\n",
    "45.28600162288954\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "68.4207720177137\n",
    ",\n",
    "126.46381782255892\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "240.69130241085875\n",
    ",\n",
    "-4.952376633358189\n",
    ",\n",
    "144.15406580582882\n",
    ",\n",
    "68.4207720177137\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "23.132069594597716\n",
    ",\n",
    "162.36267762178653\n",
    ",\n",
    "162.36267762178653\n",
    ",\n",
    "76.35777727755472\n",
    ",\n",
    "190.68087529711067\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "162.3626776217865\n",
    ",\n",
    "-18.397853638892826\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "162.36267762178653\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "190.68087529711067\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "76.3577772775547\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "15.958150733042714\n",
    ",\n",
    "52.886503898635155\n",
    ",\n",
    "37.79446623850616\n",
    ",\n",
    "84.41022893730099\n",
    ",\n",
    "15.958150733042729\n",
    ",\n",
    "23.132069594597716\n",
    ",\n",
    "37.794466238506146\n",
    ",\n",
    "-4.952376633358195\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "60.597558025674815\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "45.28600162288957\n",
    ",\n",
    "8.887082921177253\n",
    ",\n",
    "-50.36069344146\n",
    ",\n",
    "-18.39785363889282\n",
    ",\n",
    "-24.97636624056102\n",
    ",\n",
    "-37.851799131618215\n",
    ",\n",
    "45.28600162288957\n",
    ",\n",
    "-11.723654368042652\n",
    ",\n",
    "37.794466238506146\n",
    ",\n",
    "-56.48096115798327\n",
    ",\n",
    "-4.952376633358199\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "1.917391603932245\n",
    ",\n",
    "-11.723654368042652\n",
    ",\n",
    "68.4207720177137\n",
    ",\n",
    "1.9173916039322592\n",
    ",\n",
    "52.88650389863511\n",
    ",\n",
    "52.88650389863513\n",
    ",\n",
    "-4.952376633358189\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "37.79446623850616\n",
    ",\n",
    "30.410335508808643\n",
    ",\n",
    "-24.976366240561013\n",
    ",\n",
    "8.887082921177239\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "60.59755802567484\n",
    ",\n",
    "68.42077201771373\n",
    ",\n",
    "-11.723654368042654\n",
    ",\n",
    "45.28600162288957\n",
    ",\n",
    "60.59755802567483\n",
    ",\n",
    "30.410335508808664\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "100.86821270734691\n",
    ",\n",
    "135.24507862442545\n",
    ",\n",
    "84.41022893730099\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "153.19263718973983\n",
    ",\n",
    "126.46381782255892\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "52.886503898635134\n",
    ",\n",
    "23.13206959459773\n",
    ",\n",
    "153.1926371897398\n",
    ",\n",
    "52.88650389863513\n",
    ",\n",
    "117.80845221249749\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "76.3577772775547\n",
    ",\n",
    "153.19263718973983\n",
    ",\n",
    "144.15406580582882\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "68.42077201771372\n",
    ",\n",
    "84.41022893730099\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "-4.952376633358192\n",
    ",\n",
    "144.1540658058288\n",
    ",\n",
    "52.88650389863515\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "84.41022893730097\n",
    ",\n",
    "153.19263718973983\n",
    ",\n",
    "92.57980620350648\n",
    ",\n",
    "100.86821270734694\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "126.46381782255895\n",
    ",\n",
    "171.666099363308\n",
    ",\n",
    "135.24507862442542\n",
    ",\n",
    "45.28600162288956\n",
    ",\n",
    "109.27717685988407\n",
    ",\n",
    "52.886503898635134\n",
    ",\n",
    "92.57980620350651\n",
    ",\n",
    "30.41033550880865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-30.268026852649648\n",
      "17.690417579990196\n",
      "1.3660342061229178\n",
      "-14.252763169007313\n",
      "-0.4341394807814767\n",
      "-4.486038353509953\n",
      "-4.480589742850745\n",
      "-3.1840414609013967\n",
      "-6.766468724948729\n",
      "-9.063533336463841\n",
      "-12.126376977485466\n",
      "-7.21343110473829\n",
      "-3.5639482622546734\n",
      "2.258099496353668\n",
      "8.020243669359838\n",
      "13.121376689295184\n",
      "17.011371927375375\n",
      "16.509817752656485\n",
      "19.419598561303445\n",
      "23.051774213176813\n",
      "27.38216707891772\n",
      "29.597266711933973\n",
      "28.72149333779043\n",
      "27.649218006087615\n",
      "27.763086219996477\n",
      "28.695166051285405\n",
      "31.360498274056738\n",
      "33.578377711727754\n",
      "35.502075790897266\n",
      "37.565207296104845\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "for i in range(300):\n",
    "    list.append(sum(read[:(i+1)])/(i+1))\n",
    "for i in range(9, 300, 10):\n",
    "    print(list[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
